{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem Statement : Implement a Multi-Layer Perceptron (MLP) to classify digits from the MNIST dataset. Experiment with different numbers of hidden layers and neurons per layer. Compare the results in terms of accuracy and training time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values to be between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Flatten the images from 28x28 into 784-dimensional vectors\n",
    "x_train = x_train.reshape(-1, 28*28)\n",
    "x_test = x_test.reshape(-1, 28*28)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import time\n",
    "\n",
    "# Function to create an MLP model with a specific number of hidden layers and neurons\n",
    "def create_mlp(hidden_layers, neurons_per_layer):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Input layer: input_dim = 784 (since images are 28x28 flattened)\n",
    "    model.add(Dense(neurons_per_layer, input_dim=28*28, activation='relu'))\n",
    "    \n",
    "    # Hidden layers\n",
    "    for _ in range(hidden_layers - 1):\n",
    "        model.add(Dense(neurons_per_layer, activation='relu'))\n",
    "    \n",
    "    # Output layer: 10 output neurons for 10 classes\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MLP with 1 hidden layers and 64 neurons per layer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 - 3s - 7ms/step - accuracy: 0.8845 - loss: 0.4268 - val_accuracy: 0.9322 - val_loss: 0.2328\n",
      "Epoch 2/10\n",
      "469/469 - 1s - 3ms/step - accuracy: 0.9417 - loss: 0.2041 - val_accuracy: 0.9504 - val_loss: 0.1674\n",
      "Epoch 3/10\n",
      "469/469 - 2s - 3ms/step - accuracy: 0.9557 - loss: 0.1537 - val_accuracy: 0.9578 - val_loss: 0.1405\n",
      "Epoch 4/10\n",
      "469/469 - 1s - 3ms/step - accuracy: 0.9642 - loss: 0.1238 - val_accuracy: 0.9628 - val_loss: 0.1206\n",
      "Epoch 5/10\n",
      "469/469 - 2s - 3ms/step - accuracy: 0.9702 - loss: 0.1037 - val_accuracy: 0.9663 - val_loss: 0.1101\n",
      "Epoch 6/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9747 - loss: 0.0882 - val_accuracy: 0.9689 - val_loss: 0.1042\n",
      "Epoch 7/10\n",
      "469/469 - 1s - 3ms/step - accuracy: 0.9781 - loss: 0.0768 - val_accuracy: 0.9712 - val_loss: 0.0967\n",
      "Epoch 8/10\n",
      "469/469 - 1s - 3ms/step - accuracy: 0.9806 - loss: 0.0676 - val_accuracy: 0.9723 - val_loss: 0.0916\n",
      "Epoch 9/10\n",
      "469/469 - 1s - 3ms/step - accuracy: 0.9827 - loss: 0.0611 - val_accuracy: 0.9730 - val_loss: 0.0889\n",
      "Epoch 10/10\n",
      "469/469 - 2s - 5ms/step - accuracy: 0.9846 - loss: 0.0540 - val_accuracy: 0.9714 - val_loss: 0.0895\n",
      "Training MLP with 2 hidden layers and 64 neurons per layer...\n",
      "Epoch 1/10\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.8849 - loss: 0.3935 - val_accuracy: 0.9469 - val_loss: 0.1832\n",
      "Epoch 2/10\n",
      "469/469 - 2s - 5ms/step - accuracy: 0.9536 - loss: 0.1575 - val_accuracy: 0.9603 - val_loss: 0.1311\n",
      "Epoch 3/10\n",
      "469/469 - 2s - 5ms/step - accuracy: 0.9653 - loss: 0.1160 - val_accuracy: 0.9673 - val_loss: 0.1080\n",
      "Epoch 4/10\n",
      "469/469 - 2s - 5ms/step - accuracy: 0.9723 - loss: 0.0931 - val_accuracy: 0.9653 - val_loss: 0.1131\n",
      "Epoch 5/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9770 - loss: 0.0779 - val_accuracy: 0.9709 - val_loss: 0.0964\n",
      "Epoch 6/10\n",
      "469/469 - 2s - 3ms/step - accuracy: 0.9802 - loss: 0.0648 - val_accuracy: 0.9745 - val_loss: 0.0870\n",
      "Epoch 7/10\n",
      "469/469 - 1s - 3ms/step - accuracy: 0.9832 - loss: 0.0567 - val_accuracy: 0.9722 - val_loss: 0.0899\n",
      "Epoch 8/10\n",
      "469/469 - 2s - 3ms/step - accuracy: 0.9853 - loss: 0.0480 - val_accuracy: 0.9730 - val_loss: 0.0933\n",
      "Epoch 9/10\n",
      "469/469 - 2s - 3ms/step - accuracy: 0.9877 - loss: 0.0408 - val_accuracy: 0.9755 - val_loss: 0.0883\n",
      "Epoch 10/10\n",
      "469/469 - 2s - 3ms/step - accuracy: 0.9888 - loss: 0.0374 - val_accuracy: 0.9755 - val_loss: 0.0844\n",
      "Training MLP with 3 hidden layers and 128 neurons per layer...\n",
      "Epoch 1/10\n",
      "469/469 - 3s - 5ms/step - accuracy: 0.9074 - loss: 0.3151 - val_accuracy: 0.9561 - val_loss: 0.1422\n",
      "Epoch 2/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9647 - loss: 0.1167 - val_accuracy: 0.9693 - val_loss: 0.1009\n",
      "Epoch 3/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9756 - loss: 0.0803 - val_accuracy: 0.9730 - val_loss: 0.0835\n",
      "Epoch 4/10\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.9811 - loss: 0.0606 - val_accuracy: 0.9718 - val_loss: 0.0857\n",
      "Epoch 5/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9849 - loss: 0.0470 - val_accuracy: 0.9735 - val_loss: 0.0816\n",
      "Epoch 6/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9884 - loss: 0.0367 - val_accuracy: 0.9758 - val_loss: 0.0751\n",
      "Epoch 7/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9900 - loss: 0.0304 - val_accuracy: 0.9760 - val_loss: 0.0852\n",
      "Epoch 8/10\n",
      "469/469 - 3s - 7ms/step - accuracy: 0.9915 - loss: 0.0267 - val_accuracy: 0.9734 - val_loss: 0.1014\n",
      "Epoch 9/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9923 - loss: 0.0234 - val_accuracy: 0.9695 - val_loss: 0.1123\n",
      "Epoch 10/10\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.9934 - loss: 0.0205 - val_accuracy: 0.9773 - val_loss: 0.0830\n",
      "Training MLP with 2 hidden layers and 256 neurons per layer...\n",
      "Epoch 1/10\n",
      "469/469 - 3s - 6ms/step - accuracy: 0.9250 - loss: 0.2589 - val_accuracy: 0.9624 - val_loss: 0.1202\n",
      "Epoch 2/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9712 - loss: 0.0951 - val_accuracy: 0.9706 - val_loss: 0.0951\n",
      "Epoch 3/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9799 - loss: 0.0639 - val_accuracy: 0.9750 - val_loss: 0.0774\n",
      "Epoch 4/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9859 - loss: 0.0443 - val_accuracy: 0.9783 - val_loss: 0.0713\n",
      "Epoch 5/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9890 - loss: 0.0347 - val_accuracy: 0.9763 - val_loss: 0.0798\n",
      "Epoch 6/10\n",
      "469/469 - 2s - 5ms/step - accuracy: 0.9918 - loss: 0.0245 - val_accuracy: 0.9785 - val_loss: 0.0715\n",
      "Epoch 7/10\n",
      "469/469 - 2s - 5ms/step - accuracy: 0.9932 - loss: 0.0216 - val_accuracy: 0.9795 - val_loss: 0.0694\n",
      "Epoch 8/10\n",
      "469/469 - 2s - 4ms/step - accuracy: 0.9939 - loss: 0.0180 - val_accuracy: 0.9823 - val_loss: 0.0644\n",
      "Epoch 9/10\n",
      "469/469 - 2s - 3ms/step - accuracy: 0.9958 - loss: 0.0129 - val_accuracy: 0.9802 - val_loss: 0.0713\n",
      "Epoch 10/10\n",
      "469/469 - 3s - 5ms/step - accuracy: 0.9954 - loss: 0.0135 - val_accuracy: 0.9799 - val_loss: 0.0761\n",
      "Hidden Layers: 1, Neurons per Layer: 64, Accuracy: 0.9714, Training Time: 17.95 seconds\n",
      "Hidden Layers: 2, Neurons per Layer: 64, Accuracy: 0.9755, Training Time: 19.40 seconds\n",
      "Hidden Layers: 3, Neurons per Layer: 128, Accuracy: 0.9773, Training Time: 23.90 seconds\n",
      "Hidden Layers: 2, Neurons per Layer: 256, Accuracy: 0.9799, Training Time: 21.59 seconds\n"
     ]
    }
   ],
   "source": [
    "# Function to train the model and measure training time and accuracy\n",
    "def train_and_evaluate_model(hidden_layers, neurons_per_layer, x_train, y_train, x_test, y_test, epochs=10):\n",
    "    model = create_mlp(hidden_layers, neurons_per_layer)\n",
    "    \n",
    "    # Train the model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=epochs, batch_size=128, verbose=2)\n",
    "    training_time = time.time() - start_time\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return test_acc, training_time\n",
    "\n",
    "# Experiment configurations\n",
    "configs = [\n",
    "    {\"hidden_layers\": 1, \"neurons_per_layer\": 64},\n",
    "    {\"hidden_layers\": 2, \"neurons_per_layer\": 64},\n",
    "    {\"hidden_layers\": 3, \"neurons_per_layer\": 128},\n",
    "    {\"hidden_layers\": 2, \"neurons_per_layer\": 256}\n",
    "]\n",
    "\n",
    "# Store the results\n",
    "results = []\n",
    "\n",
    "# Train and evaluate for each configuration\n",
    "for config in configs:\n",
    "    print(f\"Training MLP with {config['hidden_layers']} hidden layers and {config['neurons_per_layer']} neurons per layer...\")\n",
    "    acc, training_time = train_and_evaluate_model(\n",
    "        config[\"hidden_layers\"], config[\"neurons_per_layer\"], x_train, y_train, x_test, y_test\n",
    "    )\n",
    "    results.append({\n",
    "        \"hidden_layers\": config[\"hidden_layers\"],\n",
    "        \"neurons_per_layer\": config[\"neurons_per_layer\"],\n",
    "        \"accuracy\": acc,\n",
    "        \"training_time\": training_time\n",
    "    })\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(f\"Hidden Layers: {result['hidden_layers']}, Neurons per Layer: {result['neurons_per_layer']}, Accuracy: {result['accuracy']:.4f}, Training Time: {result['training_time']:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
